{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to my Histopathologic Cancer Detection Neural Network (Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the library versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.15.0\n",
      "Python: 3.10.11\n",
      "numpy: 1.24.3\n",
      "pandas: 2.1.4\n",
      "sklearn version: 1.2.2\n",
      "sklearn path: ['c:\\\\Users\\\\Micha\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\sklearn']\n",
      "matplotlib: 3.8.2\n",
      "seaborn: 0.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"tensorflow:\", tf.__version__)\n",
    "\n",
    "# import keras\n",
    "# print(\"keras:\", keras.__version__)\n",
    "\n",
    "# import kerastuner as kt\n",
    "# print(\"kerastuner:\", kt.__version__)\n",
    "\n",
    "# import keras_tuner as kt2\n",
    "# print(\"keras_tuner:\", kt2.__version__)\n",
    "\n",
    "import platform\n",
    "print(\"Python:\", platform.python_version())\n",
    "\n",
    "import numpy as np\n",
    "print(\"numpy:\", np.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "print(\"pandas:\", pd.__version__)\n",
    "\n",
    "import sklearn\n",
    "print(\"sklearn version:\", sklearn.__version__)\n",
    "\n",
    "import sklearn\n",
    "print(\"sklearn path:\", sklearn.__path__)\n",
    "\n",
    "import matplotlib\n",
    "print(\"matplotlib:\", matplotlib.__version__)\n",
    "\n",
    "import seaborn as sns\n",
    "print(\"seaborn:\", sns.__version__)\n",
    "\n",
    "# Tensorflow: 2.15.0\n",
    "# kerastuner: 1.0.5\n",
    "# keras_tuner: 1.3.5\n",
    "# Python: 3.10.11\n",
    "# numpy: 1.24.3\n",
    "# pandas: 2.1.4\n",
    "# sklearn version: 1.2.2\n",
    "# sklearn path: ['c:\\\\Users\\\\Micha\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\sklearn']\n",
    "# matplotlib: 3.8.2\n",
    "# seaborn: 0.13.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Global random seed to make sure we can replicate any model that we create (no randomness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image recognition pre-processing practices:\n",
    "\n",
    "1. **Rescaling**: Image pixel values usually range from 0 to 255. Rescaling these values to a range of 0 to 1 by dividing each pixel by 255 is a common practice. This helps to stabilize and speed up the learning process.\n",
    "\n",
    "2. **Resizing**: Deep learning models require the input dimensions to be uniform. Resizing all images to a predetermined size is essential, especially if the original dataset contains images of various dimensions.\n",
    "\n",
    "3. **Normalization**: Beyond just rescaling, you might want to normalize the image data. This can include subtracting the mean and dividing by the standard deviation across each channel. If you have a pre-trained model, you would use the normalization statistics (mean and standard deviation) from the dataset on which the model was trained.\n",
    "\n",
    "4. **Data Augmentation**: To increase the diversity of your dataset and prevent overfitting, you can apply random transformations like rotation, shifting, flipping, zooming, and shearing. These transformations generate new training samples from the original ones by altering them slightly.\n",
    "\n",
    "5. **Color Space Conversions**: Sometimes, converting images to different color spaces (e.g., from RGB to grayscale, HSV, LAB, etc.) can help the model learn more robust features, depending on the task.\n",
    "\n",
    "6. **Image Denoising**: If the images are noisy, applying denoising algorithms can help to remove noise and improve model accuracy.\n",
    "\n",
    "7. **Edge Detection**: In certain applications, particularly those involving shape analysis, edge detection filters may be applied to highlight the edges within images.\n",
    "\n",
    "8. **Masking and Cropping**: If there are regions in the images that are not relevant to the analysis, you might want to mask or crop these regions to focus the model on the important parts of the image.\n",
    "\n",
    "9. **Histogram Equalization**: This can enhance the contrast in images, which can be beneficial if you have a dataset with varying lighting conditions.\n",
    "\n",
    "10. **Centering and Standardization**: Similar to normalization, centering the data by subtracting the mean image (computed over the training set) and standardizing, so the variance of the pixels is reduced, can be beneficial.\n",
    "\n",
    "11. **Handling Class Imbalance**: If your dataset has a class imbalance, techniques such as class weighting, oversampling the minority class, or undersampling the majority class can be considered.\n",
    "\n",
    "In practice, preprocessing steps are often determined experimentally. You might start with a simple preprocessing pipeline (like just rescaling and resizing) and then iteratively add steps that improve your model performance. It's also important to note that if you're using a pre-trained model, you should preprocess your data in the same way the original model was trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to see if each image has the same dimensions since that's important for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import os\n",
    "\n",
    "# def check_image_dimensions(directory):\n",
    "#     image_sizes = set()\n",
    "#     for img_name in os.listdir(directory):\n",
    "#         img_path = os.path.join(directory, img_name)\n",
    "#         with Image.open(img_path) as img:\n",
    "#             # Get image size\n",
    "#             size = img.size\n",
    "#             image_sizes.add(size)\n",
    "            \n",
    "#             # # If more than one size is found, we can stop checking\n",
    "#             # if len(image_sizes) > 1:\n",
    "#             #     break\n",
    "    \n",
    "#     if len(image_sizes) == 1:\n",
    "#         print(f\"For the {directory} directory, all images are of the same dimension: {image_sizes.pop()}\")\n",
    "#     else:\n",
    "#         print(f\"For the {directory} directory, different dimensions found: {image_sizes}\")\n",
    "\n",
    "# # Use it on the train and test data only if this code segment was never ran in this coding session:\n",
    "# if 'checked_image_dimensions' not in globals():\n",
    "#     # Use it on the train and test data:\n",
    "#     check_image_dimensions('train')\n",
    "#     check_image_dimensions('test')\n",
    "#     checked_image_dimensions = True\n",
    "\n",
    "# # For the train directory, all images are of the same dimension: (96, 96)\n",
    "# # For the test directory, all images are of the same dimension: (96, 96)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you need to, call the resize_images functions to ensure each image is the same dimension but make sure you are not distorting the images. In order to do this, you need to make sure all the original images have the same aspect ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    " \n",
    "\n",
    "def resize_images(directory, size=(128, 128)): \n",
    "    for img_name in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        with Image.open(img_path) as img:\n",
    "            new_img = img.resize(size)\n",
    "            new_img.save(img_path)\n",
    "\n",
    "# Use it on the train and test data if needed, and change the size argument as you need:\n",
    "            \n",
    "# resize_images('train', size=(128, 128))\n",
    "# resize_images('test', size=(128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Keras ImageDataGenerator() on Train Data\n",
    "The ImageDataGenerator not only helps you load images from the disk but also allows you to perform **data augmentation**, which is a technique to increase the diversity of your training set by applying random transformations (like rotation, zoom, flips, etc.) to the images. This is very useful to prevent overfitting and helps the model generalize better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure to change the \"target_size\" argument of the train_datagen.flow_from_dataframe() function as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 220025 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Set the base directory to the current directory\n",
    "base_dir = ''\n",
    "\n",
    "# Directories for training and test images\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Load the labels\n",
    "labels = pd.read_csv(os.path.join(base_dir, 'train_labels.csv'))\n",
    "\n",
    "# Convert the 'label' column to strings\n",
    "labels['label'] = labels['label'].astype(str)\n",
    "\n",
    "# Add the full path to the image files, and create a new column called \"path\" inside the label dataframe to store these paths to images\n",
    "labels['path'] = labels['id'].apply(lambda x: os.path.join(train_dir, f\"{x}.tif\"))\n",
    "\n",
    "labels.to_csv('labels.csv', index=False)\n",
    "\n",
    "# Creating an instance of the ImageDataGenerator for data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Rescale the image pixel values to [0,1]\n",
    "\n",
    "    # Potential data augmentation techniques that won't affect the 32x32px center\n",
    "    #brightness_range=[0.8, 1.2], \n",
    "    #channel_shift_range=20, \n",
    "\n",
    "    # I removed these transformations for the data augmentation since this project involves detecting tumor tissue in the center 32x32px region so I can't be doing zooming and other transformations for this project specifically\n",
    "\n",
    "    # rotation_range=40,  # Random rotations\n",
    "    # width_shift_range=0.2,  # Random horizontal shifts\n",
    "    # height_shift_range=0.2,  # Random vertical shifts\n",
    "    # shear_range=0.2,  # Shear transformations\n",
    "    # zoom_range=0.2,  # Random zoom\n",
    "    # horizontal_flip=True,  # Random horizontal flips\n",
    "    # fill_mode='nearest'  # Strategy for filling in new pixels\n",
    ")\n",
    "\n",
    "# Flow from dataframe method to load images using the dataframe\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=labels,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(96, 96),  # The dimensions to which all images found will be resized. Change this as needed\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary', # means that the labels are binary labels\n",
    "    batch_size=32,\n",
    "    shuffle=True, # This might introduce randomness if set to true, but if it's false, the it might lead to overfitting. So it's best to just save the neural network to ensure no randomness\n",
    "    seed=42\n",
    ")\n",
    "#print(labels['path'].head())\n",
    "# After setting this up, you can use train_generator as the input to the fit or fit_generator method of your Keras model, \n",
    "# which will load images in batches and train your model on them.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want, you can check the image shape and see a visualization of the pictures below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Get a batch of images\n",
    "# images, labels = next(train_generator)\n",
    "\n",
    "# # The images should now be a numpy array. Check its shape:\n",
    "# print(images.shape)  # Should be (batch_size, target_size[0], target_size[1], 3)\n",
    "\n",
    "# # Plot the first few images\n",
    "# for i in range(5):  # Change this value to see more images\n",
    "#     plt.figure(figsize=(5, 5))\n",
    "#     plt.imshow(images[i])\n",
    "#     plt.title(f'Label: {labels[i]}') \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split traininging data (train_generator) into train, validation, test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Maybe try GrayScale conversation\n",
    "### 2. Try Image cropping for 32x32px or 33x33px or no image cropping at all\n",
    "### 3. Try histogram equalization (part of data preprocessing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
